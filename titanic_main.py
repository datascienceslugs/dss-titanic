# -*- coding: utf-8 -*-
"""DSS_Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VDyxR58gx6uPaG5DHx0PJWROxT9zn18C
"""

# data analysis and wrangling
import pandas as pd # (1) makes importing and analyzing data much easier
import numpy as np # (2) package for scientific computing. Contains N-dimensional array object, sophisticated (broadcasting) functions, tools for integrating C/C++ and Fortran
import random as rnd # (3) test comment for 3

# visualization
import seaborn as sns # (4) Seaborn is a library for making statistical graphics in Python. It is built on top of matplotlib and closely integrated with pandas data structures.
import matplotlib.pyplot as plt # (1) a plotting library
# %matplotlib inline 
# (2) includes matplot graphs in notebook

# machine learning
from sklearn.linear_model import LogisticRegression # (3)
from sklearn.svm import SVC, LinearSVC # (4)
from sklearn.ensemble import RandomForestClassifier # (1) estimator that fits a number of decision tree classifiers on various sub-samples of the dataset.
from sklearn.neighbors import KNeighborsClassifier # (2) 
from sklearn.naive_bayes import GaussianNB # (3) 
from sklearn.linear_model import Perceptron # (4)
from sklearn.linear_model import SGDClassifier # (1)
from sklearn.tree import DecisionTreeClassifier # (2)

# load data
# https://drive.google.com/file/d/1Ij_Yjt6jkQTJi_6r0SXPZpVuX9SA-KX4/view?usp=sharing # (3)
train_file_id = '1Ij_Yjt6jkQTJi_6r0SXPZpVuX9SA-KX4' # (4)
link = 'https://drive.google.com/uc?export=download&id={FILE_ID}' # (1) link to the downloads folder of google drive 
train_csv_url = link.format(FILE_ID = train_file_id) # (2) 

# https://drive.google.com/file/d/1Vr4cNF-oOD2z3IxBVEsIeruvY8LocwQh/view?usp=sharing # (3) 
test_file_id = '1Vr4cNF-oOD2z3IxBVEsIeruvY8LocwQh' # (4)
test_csv_url = link.format(FILE_ID = test_file_id) # (1) formatting link to specific csv file



# import data into a pandas data frame
train_df = pd.read_csv(train_csv_url, sep=',') # (2)
test_df = pd.read_csv(test_csv_url, sep=',') # (3)
combine = [train_df, test_df] # (4)

print(train_df.columns.values)

train_df.info()







train_df.head()
train_df.tail()

train_df.describe()

train_df.describe(include=['O'])

# can you see this

# asjfkaw;lfja;